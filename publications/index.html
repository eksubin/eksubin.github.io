<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> publications | Subin Erattakulangara </title> <meta name="author" content="Subin Erattakulangara"> <meta name="description" content="Publications and conference abstracts"> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://eksubin.github.io/publications/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Subin</span> Erattakulangara </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item active"> <a class="nav-link" href="/publications/">publications <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects </a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">repositories </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">publications</h1> <p class="post-description">Publications and conference abstracts</p> </header> <article> <script src="/assets/js/bibsearch.js?1bc438ca9037884cc579601c09afd847" type="module"></script> <p><input type="text" id="bibsearch" spellcheck="false" autocomplete="off" class="search bibsearch-form-input" placeholder="Type to filter"></p> <div class="publications"> <h2 class="bibliography">2025</h2> <ol class="bibliography"><li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">Segmentation</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/jov-480.webp 480w,/assets/img/publication_preview/jov-800.webp 800w,/assets/img/publication_preview/jov-1400.webp 1400w," type="image/webp" sizes="200px"></source> <img src="/assets/img/publication_preview/jov.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="jov.jpg" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="paper4" class="col-sm-8"> <div class="title">Open-Source Manually Annotated Vocal Tract Database for Automatic Segmentation from 3D MRI Using Deep Learning: Benchmarking 2D and 3D Convolutional and Transformer Networks (Under Review)</div> <div class="author"> </div> <div class="periodical"> <em>Journal of Voice</em>, 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://arxiv.org/abs/2501.06229" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="abstract hidden"> <p>Accurate segmentation of the vocal tract from magnetic resonance imaging (MRI) data is essential for various voice and speech applications. Manual segmentation is time-intensive and susceptible to errors. This study aimed to evaluate the efficacy of deep learning algorithms for automatic vocal tract segmentation from 3D MRI.</p> </div> </div> </div> </li></ol> <h2 class="bibliography">2023</h2> <ol class="bibliography"><li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">Segmentation</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/bioeng.webp" sizes="200px"></source> <img src="/assets/img/publication_preview/bioeng.webp" class="preview z-depth-1 rounded" width="100%" height="auto" alt="bioeng.webp" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="paper3" class="col-sm-8"> <div class="title">Automatic Multiple Articulator Segmentation in Dynamic Speech MRI Using a Protocol Adaptive Stacked Transfer Learning U-NET Model</div> <div class="author"> </div> <div class="periodical"> <em>Bioengineering</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://www.mdpi.com/2306-5354/10/5/623" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="abstract hidden"> <p>Dynamic magnetic resonance imaging (MRI) is a valuable technique for studying upper-airway function during speech production by analyzing changes in vocal tract airspace and the positioning of soft-tissue articulators. This paper introduces a stacked transfer learning U-NET model aimed at segmenting the deforming vocal tract in 2D mid-sagittal slices of dynamic speech MRI. The model utilizes both low- and mid-level features from pre-trained datasets (brain tumor MR, lung CT, and an in-house airway dataset) and high-level features from protocol-specific MR images. Demonstrated across three fast speech MRI protocols with varying acquisition schemes and speech tasks, the method achieved accurate segmentations comparable to expert human annotators, even with limited protocol-specific images. Evaluation metrics included the DICE similarity coefficient, Hausdorff distance, and segmentation count, affirming the modelâ€™s effectiveness and adaptability across different MRI protocols.</p> </div> </div> </div> </li></ol> <h2 class="bibliography">2022</h2> <ol class="bibliography"><li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">Reconstruction</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/miccai.webp" sizes="200px"></source> <img src="/assets/img/publication_preview/miccai.webp" class="preview z-depth-1 rounded" width="100%" height="auto" alt="miccai.webp" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="paper2" class="col-sm-8"> <div class="title">Accelerated Pseudo 3D Dynamic Speech MR Imaging at 3T Using Unsupervised Deep Variational Manifold Learning</div> <div class="author"> </div> <div class="periodical"> <em>MICCAI</em>, 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://link.springer.com/chapter/10.1007/978-3-031-16446-0_66" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="abstract hidden"> <p>This work presents a novel approach using unsupervised deep variational manifold learning to enhance magnetic resonance imaging (MRI) of the vocal tract during speech. By recovering a "pseudo-3D" dynamic speech dataset from sequential 2D slices, the method achieves high temporal resolution (18 ms) while addressing the limitations of current volumetric MR techniques, which struggle with spatio-temporal resolution, organ coverage, and signal-to-noise ratio. The approach utilizes a 3D convolutional neural network to create volumes of the vocal tract, enforcing conditions for smoothness, regularization, and data consistency. Evaluated using in-vivo data from normal volunteers, this method allows for the first-time extraction of quantitative 3D vocal tract area functions from under-sampled 2D datasets, aiding in the understanding of vocal tract shape changes during speech</p> </div> </div> </div> </li></ol> <h2 class="bibliography">2020</h2> <ol class="bibliography"><li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">Segmentation</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/isbi2020.webp" sizes="200px"></source> <img src="/assets/img/publication_preview/isbi2020.webp" class="preview z-depth-1 rounded" width="100%" height="auto" alt="isbi2020.webp" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="conference1" class="col-sm-8"> <div class="title">Airway segmentation in speech MRI using the U-net architecture</div> <div class="author"> Sajan Goud Lingala Subin Erattakulangara </div> <div class="periodical"> <em>International Symposium on Biomedical Imaging (ISBI)</em>, 2020 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://ieeexplore.ieee.org/abstract/document/9098536" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="abstract hidden"> <p>We develop a fully automated airway segmentation method to segment the vocal tract airway from surrounding soft tissue in speech MRI. We train a U-net architecture to learn the end to end mapping between a mid-sagittal image (at the input), and the manually segmented airway (at the output). We base our training on the open source University of Southern Californiaâ€™s (USC) speech morphology MRI database consisting of speakers producing a variety of sustained vowel and consonant sounds. Once trained, our model performs fast airway segmentations on unseen images at the order of 210 ms/slice on a modern CPU with 12 cores. Using manual segmentation as a reference, we evaluate the performances of the proposed U-net airway segmentation, against existing seed-growing segmentation, and manual segmentation from a different user.</p> </div> </div> </div> </li></ol> <h2 class="bibliography">2019</h2> <ol class="bibliography"><li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">Genetics</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/paper1.webp" sizes="200px"></source> <img src="/assets/img/publication_preview/paper1.webp" class="preview z-depth-1 rounded" width="100%" height="auto" alt="paper1.webp" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="paper1" class="col-sm-8"> <div class="title">Network Analysis of MPO and Other Relevant Proteins Involved in Diabetic Foot Ulcer and Other Diabetic Complications</div> <div class="author"> T. V. Suchithra Mathew Saumya </div> <div class="periodical"> <em>Interdisciplinary Sciences: Computational Life Sciences</em>, 2019 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://link.springer.com/article/10.1007/s12539-017-0258-z" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="abstract hidden"> <p>Network analysis and visualization of genes are very important to understand large complex biological data in a better manner. Large data on genes and proteins in the biological systems are analyzed on the occurrence, interactions, co-expression, and co-regulations of various genes. Here we have visualized the genes involved in type 1 diabetes (T1D), type 2 diabetes (T2D), and foot ulcer condition to put light on the corrective measures to the problem of impaired healing. The goal of this study was to identify the important genes involved in the pathogenesis of diabetes complications and foot ulcer and its association with the free radical-producing enzyme, the myeloperoxidase (MPO). In this study, we have used bioinformatics tools for the analysis of 24 genes that play a major role in diabetes mellitus and its complications, especially diabetic foot ulcer to reveal the relation between the genes and proteins involved in these disease conditions. We could conclude from the network model that MPO is related to foot ulcer and involved in pathogenesis of various co-associated diseases, such as oxidative stress, inflammation, peripheral vascular disease, and other related diabetes complications</p> </div> </div> </div> </li></ol> <h2 class="bibliography">2016</h2> <ol class="bibliography"><li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">Signal Processing</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/ijcsit-480.webp 480w,/assets/img/publication_preview/ijcsit-800.webp 800w,/assets/img/publication_preview/ijcsit-1400.webp 1400w," type="image/webp" sizes="200px"></source> <img src="/assets/img/publication_preview/ijcsit.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="ijcsit.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="paper5" class="col-sm-8"> <div class="title">Java implementation of low pass Butterworth filter for biomedical applications</div> <div class="author"> Krishna Chaitanya Subin Erattakulangara </div> <div class="periodical"> <em> International Journal of Computer Science and Information Technologies</em>, 2016 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://www.ijcsit.com/docs/Volume%207/vol7issue5/ijcsit20160705029.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="abstract hidden"> <p>Signal Processing have become an integral part of biomedical devices. In most of the cases, hardware filters are used for the removal of noise in the input signal which often lead to an increased power consumption. This problem can be rectified by implementing hardware filters in java. In this paper, low pass Butterworth filter is implemented in java by analysing ECG samples.</p> </div> </div> </div> </li></ol> </div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> Â© Copyright 2025 Subin Erattakulangara. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script>let searchTheme=determineComputedTheme();const ninjaKeys=document.querySelector("ninja-keys");"dark"===searchTheme?ninjaKeys.classList.add("dark"):ninjaKeys.classList.remove("dark");const openSearchModal=()=>{const e=$("#navbarNav");e.hasClass("show")&&e.collapse("hide"),ninjaKeys.open()};</script> <script>const ninja=document.querySelector("ninja-keys");ninja.data=[{id:"nav-about",title:"About",section:"Navigation",handler:()=>{window.location.href="/"}},{id:"nav-blog",title:"blog",description:"",section:"Navigation",handler:()=>{window.location.href="/blog/"}},{id:"nav-publications",title:"publications",description:"Publications and conference abstracts",section:"Navigation",handler:()=>{window.location.href="/publications/"}},{id:"nav-projects",title:"projects",description:"",section:"Navigation",handler:()=>{window.location.href="/projects/"}},{id:"nav-repositories",title:"repositories",description:"",section:"Navigation",handler:()=>{window.location.href="/repositories/"}},{id:"nav-cv",title:"cv",description:"",section:"Navigation",handler:()=>{window.location.href="/cv/"}},{id:"post-monailabellite-a-lightweight-implementation-of-monailabel-for-docker",title:"MonaiLabelLite - A lightweight implementation of MonaiLabel for Docker",description:"Latest Monai Label is too heavy for a docker image, Let&#39;s make it lighter",section:"Posts",handler:()=>{window.location.href="/blog/2025/2025/"}},{id:"post-building-a-clstm-cell-for-4d-data",title:"Building a CLSTM cell for 4D Data",description:"Tutorial on how to build a convolutional LSTM for 4D Data",section:"Posts",handler:()=>{window.location.href="/blog/2025/code/"}},{id:"news-multiple-iowa-city-entrepreneurs-accepted-into-accelerated-program",title:"Multiple Iowa City entrepreneurs accepted into accelerated program",description:"",section:"News",handler:()=>{window.location.href="/news/announcement_1/"}},{id:"news-bme-student-wins-sharks-top-choice-award",title:"BME student wins Sharks\u2019 Top Choice award",description:"",section:"News",handler:()=>{window.location.href="/news/announcement_2/"}},{id:"news-local-entrepreneurs-accepted-to-accelerator-program",title:"Local entrepreneurs accepted to accelerator program",description:"",section:"News",handler:()=>{window.location.href="/news/announcement_3/"}},{id:"news-international-photo-contest-first-prize",title:"International photo contest First prize",description:"",section:"News",handler:()=>{window.location.href="/news/announcement_4/"}},{id:"projects-rag-pdf-helper",title:"RAG PDF Helper",description:"The RAG PDF Helper is an application that enables users to ask questions about a PDF document loaded into the system.",section:"Projects",handler:()=>{window.location.href="/projects/1_project/"}},{id:"projects-remarkable-rss-feed",title:"Remarkable RSS Feed",description:"Remarkable RSS Feed system using Googlve Drive.",section:"Projects",handler:()=>{window.location.href="/projects/2_project/"}},{id:"projects-bridge-ai-hub",title:"Bridge AI Hub",description:"Platform for deploying AI based applications on cloud.",section:"Projects",handler:()=>{window.location.href="/projects/3_project/"}},{id:"projects-4d-time-resolved-unet",title:"4D time resolved Unet",description:"A custom Unet architecture that can handle 3D + time data.",section:"Projects",handler:()=>{window.location.href="/projects/4_project/"}},{id:"projects-4d-time-resolved-ssl-unet",title:"4D time resolved SSL Unet",description:"A Self supervised Unet architecture that can handle 3D + time data.",section:"Projects",handler:()=>{window.location.href="/projects/5_project/"}},{id:"socials-email",title:"Send email",section:"Socials",handler:()=>{window.open("mailto:%65%72%61%74%74%61%6B%75%6C%61%6E%67%61%72%61@%75%69%6F%77%61.%65%64%75","_blank")}},{id:"socials-google-scholar",title:"Google Scholar",section:"Socials",handler:()=>{window.open("https://scholar.google.com/citations?user=qc6CJjYAAAAJ","_blank")}},{id:"socials-rss",title:"RSS Feed",section:"Socials",handler:()=>{window.open("/feed.xml","_blank")}},{id:"light-theme",title:"Change theme to light",description:"Change the theme of the site to Light",section:"Theme",handler:()=>{setThemeSetting("light")}},{id:"dark-theme",title:"Change theme to dark",description:"Change the theme of the site to Dark",section:"Theme",handler:()=>{setThemeSetting("dark")}},{id:"system-theme",title:"Use system default theme",description:"Change the theme of the site to System Default",section:"Theme",handler:()=>{setThemeSetting("system")}}];</script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>